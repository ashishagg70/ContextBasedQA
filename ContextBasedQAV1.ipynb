{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ContextBasedQAV1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishagg70/ContextBasedQA/blob/master/ContextBasedQAV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kekUt8v-quR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb648be-cfda-4ad0-c397-ae366d8c9086"
      },
      "source": [
        "!wget \"https://data.deepai.org/squad1.1.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 17:15:50--  https://data.deepai.org/squad1.1.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 138.201.36.183\n",
            "Connecting to data.deepai.org (data.deepai.org)|138.201.36.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9152254 (8.7M) [application/x-zip-compressed]\n",
            "Saving to: ‘squad1.1.zip.1’\n",
            "\n",
            "squad1.1.zip.1      100%[===================>]   8.73M  4.10MB/s    in 2.1s    \n",
            "\n",
            "2021-04-18 17:15:54 (4.10 MB/s) - ‘squad1.1.zip.1’ saved [9152254/9152254]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrRUlX-PAweX",
        "outputId": "15f9b1aa-c12e-4ab7-f7c7-067cfd5daff7"
      },
      "source": [
        "!unzip squad1.1.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  squad1.1.zip\n",
            "replace dev-v1.1.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c3BWjc-B4FC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a31b32-d6ea-4905-d8d9-0ab5e112b0e7"
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.vocab import GloVe\n",
        "import json\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyqvIyLTBw37"
      },
      "source": [
        "file = open('train-v1.1.json','r')\n",
        "file2 = open('dev-v1.1.json','r')\n",
        "train_data = json.load(file)['data']\n",
        "dev_data = json.load(file2)['data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ8l5Bw91057"
      },
      "source": [
        "MAX_WORD_LENGTH = 40\n",
        "D = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPdx76dabgJw"
      },
      "source": [
        "glove = GloVe('6B',100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D8lLh6QOrNJ"
      },
      "source": [
        "char_to_index = defaultdict(int)\n",
        "index_to_char = defaultdict(str)\n",
        "word_to_index = defaultdict(int)\n",
        "index_to_word = defaultdict(str)\n",
        "\n",
        "num_contexts = 0\n",
        "num_questions = 0\n",
        "num_characters = 0\n",
        "num_words = 0\n",
        "\n",
        "char_contexts = []\n",
        "char_questions = []\n",
        "\n",
        "word_contexts=[]\n",
        "word_questions = []\n",
        "answers = []\n",
        "\n",
        "input_data = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcyBJLwIGEXD"
      },
      "source": [
        "def char_encode(text, is_train=True):\n",
        "    global char_to_index\n",
        "    global index_to_char\n",
        "    global num_characters\n",
        "\n",
        "    text_endcoding = []\n",
        "    for word in text:\n",
        "        encoding = np.zeros(MAX_WORD_LENGTH)\n",
        "        try:\n",
        "            i=0\n",
        "            for char in word:\n",
        "                encode = char_to_index[char]\n",
        "                if is_train == True and encode == 0:\n",
        "                    index = num_characters+1\n",
        "                    char_to_index[char]= index\n",
        "                    index_to_char[index]= char\n",
        "                    encode = index\n",
        "                    num_characters+=1\n",
        "                encoding[i]=encode\n",
        "                i+=1\n",
        "        except:\n",
        "            print(word)\n",
        "        text_endcoding.append(encoding)\n",
        "    return text_endcoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oMBDEgAsWbW",
        "outputId": "6d3846c7-2d10-458b-a62b-970d39dd67c7"
      },
      "source": [
        "char_encode(['this','is','good'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1., 2., 3., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.]),\n",
              " array([3., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.]),\n",
              " array([5., 6., 6., 7., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4gs1MmVXaJm"
      },
      "source": [
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def perform_word_tokenization(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def word_encode(text, is_train=True):\n",
        "    global word_to_index\n",
        "    global index_to_word\n",
        "    global num_words\n",
        "    encoding =[]\n",
        "    for word in text:\n",
        "        encode = word_to_index[word]\n",
        "        if is_train == True and encode == 0:\n",
        "            index = num_words+1\n",
        "            word_to_index[word] = index\n",
        "            index_to_word[index] = word\n",
        "            encode = index\n",
        "            num_words+=1\n",
        "        encoding.append(encode)\n",
        "    return encoding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D2yQ_1Hpo9E"
      },
      "source": [
        "def text_preprocess(text, is_train=True):\n",
        "    text = convert_to_lower(text)\n",
        "    text = perform_word_tokenization(text)\n",
        "    word_encoding = word_encode(text, is_train)\n",
        "    char_encoding = char_encode(text, is_train)\n",
        "    return char_encoding, word_encoding\n",
        "\n",
        "def get_answer_end_index(start,answer):\n",
        "    return start+len(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWkU59lnXcvm"
      },
      "source": [
        "for obj in train_data:\n",
        "    for para in obj['paragraphs']:\n",
        "        cce, cwe = text_preprocess(para['context'])\n",
        "        char_contexts.append(cce)\n",
        "        word_contexts.append(cwe)\n",
        "        num_contexts+=1\n",
        "        for qa in para['qas']:\n",
        "            qce, qwe = text_preprocess(qa['question'])\n",
        "            char_questions.append(qce)\n",
        "            word_questions.append(qwe)\n",
        "            num_questions+=1\n",
        "            input_data.append((num_contexts,num_questions))\n",
        "            ans = [] \n",
        "            for a in qa['answers']:\n",
        "                ans.append((a['answer_start'],get_answer_end_index(a['answer_start'],a['text'])))\n",
        "            answers.append(ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQQTawJsyIuH"
      },
      "source": [
        "char_vocab_size = len(char_to_index)+1\n",
        "word_vocab_size = len(word_to_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmu2m_5ovDt1"
      },
      "source": [
        "class Char_Embedding(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab_size,embedding_dim = 8, cnn_kernel_size = 5,word_embedding_size =100 ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim,padding_idx=0)\n",
        "        self.cnn = nn.Conv1d(in_channels=embedding_dim,out_channels=word_embedding_size,kernel_size=cnn_kernel_size)\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size = MAX_WORD_LENGTH-cnn_kernel_size+1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        # print(\"start\",x.shape)\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.view(-1,MAX_WORD_LENGTH)\n",
        "        x = self.embedding(x)\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.cnn(x)\n",
        "        # print(\"cnn\",x.shape)\n",
        "        x = self.maxpool(x)\n",
        "        # print(\"pool\",x.shape)\n",
        "        #TODO : ReLU \n",
        "        x = x.view(batch_size,-1,x.shape[1])\n",
        "        # print(\"final\",x.shape)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpPWBZflPsme"
      },
      "source": [
        "class Word_Embedding(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()      \n",
        "        emb_matrix = torch.zeros(word_vocab_size,100)\n",
        "        for word, idx in word_to_index.items():\n",
        "            try:\n",
        "                emb_matrix[idx, :] = embedding[word]\n",
        "            except:\n",
        "                pass\n",
        "        self.embedding = nn.Embedding.from_pretrained(emb_matrix)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.embedding(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFiEedGLXNUQ"
      },
      "source": [
        "class Contextual_Embedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bilstm = nn.LSTM(2*D,D,1,bidirectional = True,batch_first = True)\n",
        "\n",
        "    def forward(self,char_embedding,word_embedding):\n",
        "\n",
        "        x = torch.cat((char_embedding,word_embedding),dim = -1)\n",
        "\n",
        "        x,_ = self.bilstm(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udU65UyxlAoZ"
      },
      "source": [
        "class AttentionFlowLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.alpha = nn.Linear(6*D,1)\n",
        "    \n",
        "    def forward(self,H,U):\n",
        "        # H : contextual embedding of context\n",
        "        # U : contextual embedding of query\n",
        "\n",
        "        T = H.shape[1]\n",
        "        J = U.shape[1]\n",
        "\n",
        "        H_interleaved = torch.repeat_interleave(H,J,dim=1)\n",
        "        U_repeated = U.repeat(1,T,1)\n",
        "\n",
        "        assert(H_interleaved.shape==U_repeated.shape)\n",
        "\n",
        "        HU = torch.cat((H_interleaved,U_repeated,H_interleaved*U_repeated),dim=-1)\n",
        "        S = self.alpha(HU)\n",
        "        S = S.view(-1,T,J)\n",
        "        C2Q_att = F.softmax(S,dim = -1)\n",
        "        U_tilde = torch.matmul(C2Q_att,U)\n",
        "        Q2C_att = F.softmax(torch.max(S,dim=-1)[0],dim=-1)\n",
        "        Q2C_att = Q2C_att.unsqueeze(1)\n",
        "        H_tilde = torch.matmul(Q2C_att,H).repeat(1,T,1)\n",
        "        G = torch.cat((H,U_tilde,H*U_tilde,H*H_tilde),dim=-1)\n",
        "        return G\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2UgY5lb7WIg"
      },
      "source": [
        "class ModellingLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bilstm = nn.LSTM(8*D,D,2,bidirectional = True,batch_first = True)\n",
        "    def forward(self,G):\n",
        "        M,_ = self.bilstm(G)\n",
        "        return M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3SaUZ93_Zsm"
      },
      "source": [
        "class OutputLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense1 = nn.Linear(10*D,1)\n",
        "        self.dense2 = nn.Linear(10*D,1)\n",
        "        self.bilstm = nn.LSTM(2*D,D,1,bidirectional = True,batch_first = True)\n",
        "    def forward(self,G,M):\n",
        "        GM = torch.cat((G,M),dim=-1)\n",
        "        start = F.log_softmax(self.dense1(GM),dim=-1)\n",
        "        M2,_ = self.bilstm(M)\n",
        "        GM2= torch.cat((G,M2),dim=-1)\n",
        "        end = F.log_softmax(self.dense1(GM2),dim=-1)\n",
        "\n",
        "        return start.squeeze(-1),end.squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68KnieuIHCuG"
      },
      "source": [
        "class BiDAF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.char_emb_layer=Char_Embedding(char_vocab_size,embedding_dim=8)\n",
        "        self.word_emb_layer=Word_Embedding()\n",
        "        self.cont_emb_layer=Contextual_Embedding()\n",
        "        self.att_layer = AttentionFlowLayer()\n",
        "        self.modelling_layer = ModellingLayer()\n",
        "        self.output_layer = OutputLayer()\n",
        "    \n",
        "    def forward(self,context_char,context_word,query_char,query_word):\n",
        "        context_char_emb = self.char_emb_layer(char_batch_context_t)\n",
        "        context_word_emb = self.word_emb_layer(word_batch_context_t)\n",
        "        context_cont_emb = self.cont_emb_layer(context_char_emb,context_word_emb)\n",
        "\n",
        "        query_char_emb = self.char_emb_layer(char_batch_query_t)\n",
        "        query_word_emb = self.word_emb_layer(word_batch_query_t)\n",
        "        query_cont_emb = self.cont_emb_layer(query_char_emb,query_word_emb)\n",
        "\n",
        "        g =self.att_layer(context_cont_emb,query_cont_emb)\n",
        "        m = modelling(g)\n",
        "        o = output_layer(g,m)\n",
        "        return o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0dV56dIzt58"
      },
      "source": [
        "char_batch_context = [char_contexts[0],char_contexts[0]]\n",
        "char_batch_query = [char_questions[0],char_questions[1]]\n",
        "word_batch_context=[word_contexts[0],word_contexts[0]]\n",
        "word_batch_query = [word_questions[0],word_questions[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utt6W-Oi3mBx"
      },
      "source": [
        "char_batch_context_t = torch.LongTensor(nn.utils.rnn.pad_sequence([torch.LongTensor(sent) for sent in char_batch_context],batch_first=True))\n",
        "char_batch_query_t = torch.LongTensor(nn.utils.rnn.pad_sequence([torch.LongTensor(sent) for sent in char_batch_query],batch_first=True))\n",
        "word_batch_context_t = torch.LongTensor(nn.utils.rnn.pad_sequence([torch.LongTensor(sent) for sent in word_batch_context],batch_first=True))\n",
        "word_batch_query_t = torch.LongTensor(nn.utils.rnn.pad_sequence([torch.LongTensor(sent) for sent in word_batch_query],batch_first=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ZFT7uoK-2m"
      },
      "source": [
        "bidaf = BiDAF()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOJod0uoLCCM"
      },
      "source": [
        "o = bidaf(char_batch_context_t,word_batch_context_t,char_batch_query_t,word_batch_query_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5nAg2p3Dm-B"
      },
      "source": [
        "tot = 0\n",
        "for param in bidaf.parameters():\n",
        "    if param.requires_grad==True:\n",
        "        tot+=param.numel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O5FqEIjLnf2",
        "outputId": "abbe3d7f-3116-4130-9cb2-58ab9a971e61"
      },
      "source": [
        "tot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1625003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOiJOyfpLr2M",
        "outputId": "8325a627-3476-4b67-884c-134ca4f0d9f7"
      },
      "source": [
        "bidaf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiDAF(\n",
              "  (char_emb_layer): Char_Embedding(\n",
              "    (embedding): Embedding(1259, 100, padding_idx=0)\n",
              "    (cnn): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    (maxpool): MaxPool1d(kernel_size=36, stride=36, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (word_emb_layer): Word_Embedding(\n",
              "    (embedding): Embedding(103079, 100)\n",
              "  )\n",
              "  (cont_emb_layer): Contextual_Embedding(\n",
              "    (bilstm): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (att_layer): AttentionFlowLayer(\n",
              "    (alpha): Linear(in_features=600, out_features=1, bias=True)\n",
              "  )\n",
              "  (modelling_layer): ModellingLayer(\n",
              "    (bilstm): LSTM(800, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (output_layer): OutputLayer(\n",
              "    (dense1): Linear(in_features=1000, out_features=1, bias=True)\n",
              "    (dense2): Linear(in_features=1000, out_features=1, bias=True)\n",
              "    (bilstm): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5nPLT92Mc0g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}